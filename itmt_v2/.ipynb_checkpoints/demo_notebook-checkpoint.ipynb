{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5f166ea",
   "metadata": {},
   "source": [
    "## Demo inference on MRI T1 image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73938c9f",
   "metadata": {},
   "source": [
    "Data source: MRI data of 3-12 year old children and adults during viewing of a short animated film\n",
    "https://openneuro.org/datasets/ds000228/versions/1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83daae0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 19:21:34.033980: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-07 19:21:34.270867: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-07 19:21:34.307729: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-07-07 19:21:34.873182: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/user/anaconda3/envs/tf2_py39/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda/lib64\n",
      "2023-07-07 19:21:34.873247: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/user/anaconda3/envs/tf2_py39/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda/lib64\n",
      "2023-07-07 19:21:34.873252: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import generators\n",
    "\n",
    "import logging\n",
    "import glob, os, functools\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import SimpleITK as sitk\n",
    "from scipy.signal import medfilt\n",
    "import numpy as np\n",
    "from numpy import median\n",
    "import scipy\n",
    "import nibabel as nib\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "from scipy import ndimage\n",
    "from skimage.transform import resize,rescale\n",
    "import cv2\n",
    "import itk\n",
    "import subprocess\n",
    "from intensity_normalization.typing import Modality, TissueType\n",
    "from intensity_normalization.normalize.zscore import ZScoreNormalize\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2 \n",
    "from compute_population_pred import major_voting, measure_tm, filter_islands,compute_crop_line\n",
    "  \n",
    "from scripts.densenet_regression import DenseNet\n",
    "from scripts.unet import get_unet_2D\n",
    "from scripts.preprocess_utils import load_nii,save_nii, find_file_in_path,iou, register_to_template,enhance_noN4,crop_center, get_id_and_path\n",
    "from scripts.feret import Calculater\n",
    "from settings import  target_size_dense_net, target_size_unet, unet_classes, softmax_threshold, major_voting,scaling_factor\n",
    "from scripts.infer_selection import get_slice_number_from_prediction, funcy\n",
    "from scripts.preprocess_utils import closest_value,find_centile,find_exact_percentile_return_number,add_median_labels\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '3'\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f35cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = np.load('../data/segmentations_itmt2.0/train_images.npy')\n",
    "train_masks = np.load('../data/segmentations_itmt2.0/train_masks.npy')\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3c702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in range(0, np.asarray(train_masks).shape[0]):\n",
    "    fg=plt.figure(figsize=(5, 5), facecolor='k')\n",
    "    plt.imshow(train_imgs[img,:,:,0],'gray')\n",
    "    plt.imshow(train_masks[img,:,:,0], 'Blues', alpha=0.2, interpolation='none')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023b1a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = np.load('../data/segmentations_itmt2.0/train_images.npy')\n",
    "train_masks = np.load('../data/segmentations_itmt2.0/train_masks.npy')\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e695b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in range(0, np.asarray(train_masks).shape[0]):\n",
    "    fg=plt.figure(figsize=(5, 5), facecolor='k')\n",
    "    plt.imshow(train_imgs[img,:,:,0],'gray')\n",
    "    plt.imshow(train_masks[img,:,:,0], 'Blues', alpha=0.2, interpolation='none')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "065d643e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 ('L', 'P', 'S') ('L', 'P', 'S')\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 3-dimensional, but 4 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 75\u001b[0m\n\u001b[1;32m     72\u001b[0m df_val \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain/test\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m#df_val = df_val[df_val['Ok registered? Y/N']=='Y'].reset_index()\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m \u001b[43mnifty_to_npy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_images_array\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/segmentations_itmt2.0/train_images.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m             \u001b[49m\u001b[43mpath_masks_array\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/segmentations_itmt2.0/train_masks.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [19], line 49\u001b[0m, in \u001b[0;36mnifty_to_npy\u001b[0;34m(df, path_images_array, path_masks_array)\u001b[0m\n\u001b[1;32m     46\u001b[0m masks_array[\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mdf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39midx,:,:,:] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((rescaled_mask[:,\u001b[38;5;241m256\u001b[39m:,:,:],np\u001b[38;5;241m.\u001b[39mzeros_like(rescaled_image[:,\u001b[38;5;241m256\u001b[39m:,:,:])),axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     48\u001b[0m fg\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m), facecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mimage_array\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     50\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(masks_array[\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mdf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39midx,:,:,\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m'\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     51\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2_py39/lib/python3.9/site-packages/numpy/core/memmap.py:334\u001b[0m, in \u001b[0;36mmemmap.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 334\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(res) \u001b[38;5;129;01mis\u001b[39;00m memmap \u001b[38;5;129;01mand\u001b[39;00m res\u001b[38;5;241m.\u001b[39m_mmap \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mndarray)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 3-dimensional, but 4 were indexed"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert nifti to numpy array\n",
    "def nifty_to_npy(df, path_images_array, path_masks_array):  \n",
    "    # create empty arrays for populating with image slices\n",
    "    images_array  = np.zeros((df.shape[0]*4, target_size_unet[0], target_size_unet[1], 1))\n",
    "    masks_array  = np.zeros((df.shape[0]*4, target_size_unet[0], target_size_unet[1], 1))\n",
    "\n",
    "    for idx in range(900,len(df)):\n",
    "        row=df.iloc[idx]\n",
    "        #print(idx)\n",
    "        patient_id, image_path, tm_file, _ = get_id_and_path(row, image_dir)\n",
    "        #NDAR processed differently\n",
    "        \n",
    "        if image_path != 0:\n",
    "            seg = nib.load(tm_file)\n",
    "            seg_data, seg_affine  = seg.get_fdata(), seg.affine\n",
    "            if len(seg_data)>3:\n",
    "                #print(np.asarray(nib.aff2axcodes(seg_affine)))\n",
    "                     \n",
    "                if 'gz' in image_path :\n",
    "                    os.rename(image_path,image_path.split('.gz')[0])\n",
    "                    image_path = image_path.split('.gz')[0]\n",
    "                    image_array, img_aff = load_nii(image_path)\n",
    "                else:\n",
    "                    image_array, img_aff = load_nii(image_path)\n",
    "                    \n",
    "                \n",
    "                if (np.asarray(nib.aff2axcodes(seg_affine))==['L', 'P', 'S']).all() or\\\n",
    "                (np.asarray(nib.aff2axcodes(seg_affine))==['R', 'A', 'S']).all():\n",
    "                    slice_label = np.asarray(np.where(seg_data != 0)).T[0, 2] \n",
    "                \n",
    "                print(idx, nib.aff2axcodes(seg_affine),nib.aff2axcodes(img_aff))\n",
    "                \n",
    "                # rescale to 512x512\n",
    "                rescaled_mask  = rescale(seg_data[:,15:-21,slice_label], scaling_factor).reshape(1,target_size_unet[0],target_size_unet[1],1) \n",
    "                rescaled_image = rescale(image_array[:,15:-21,slice_label], scaling_factor).reshape(1,target_size_unet[0],target_size_unet[1],1) \n",
    "                \n",
    "                \n",
    "                \n",
    "                images_array[idx,:,:,:] = np.concatenate((rescaled_image[:,:256,:,:],np.zeros_like(rescaled_image[:,:256,:,:])),axis=1)\n",
    "                masks_array[idx,:,:,:] = np.concatenate((rescaled_mask[:,:256,:,:],np.zeros_like(rescaled_mask[:,:256,:,:])),axis=1)\n",
    "                images_array[df.shape[0]+idx,:,:,:] = np.concatenate((np.zeros_like(rescaled_image[:,256:,:,:]),rescaled_image[:,256:,:,:]),axis=1)\n",
    "                masks_array[df.shape[0]+idx,:,:,:] = np.concatenate((np.zeros_like(rescaled_image[:,256:,:,:]),rescaled_mask[:,256:,:,:]),axis=1)\n",
    "                images_array[2*df.shape[0]+idx,:,:,:] = np.concatenate((np.zeros_like(rescaled_image[:,:256,:,:]),rescaled_image[:,:256,:,:]),axis=1)\n",
    "                masks_array[2*df.shape[0]+idx,:,:,:] = np.concatenate((np.zeros_like(rescaled_image[:,:256,:,:]),rescaled_mask[:,:256,:,:]),axis=1)\n",
    "                images_array[3*df.shape[0]+idx,:,:,:] = np.concatenate((rescaled_image[:,256:,:,:],np.zeros_like(rescaled_image[:,256:,:,:])),axis=1)\n",
    "                masks_array[3*df.shape[0]+idx,:,:,:] = np.concatenate((rescaled_mask[:,256:,:,:],np.zeros_like(rescaled_image[:,256:,:,:])),axis=1)\n",
    "                \n",
    "                fg=plt.figure(figsize=(5, 5), facecolor='k')\n",
    "                print(np.shape(image_array[3*df.shape[0]+idx,:,:,0]))\n",
    "                plt.imshow(image_array[3*df.shape[0]+idx,:,:,0],'gray')\n",
    "                plt.imshow(masks_array[3*df.shape[0]+idx,:,:,0], 'Blues', alpha=0.2, interpolation='none')\n",
    "                plt.show()\n",
    "                \n",
    "                #print(idx, patient_id, np.shape(images_array[idx,:,:,:]),np.shape(masks_array[idx,:,:,:]))\n",
    "                if np.sum(masks_array[idx,:,:,:])<=15 or np.sum(masks_array[df.shape[0]+idx,:,:,:])<=15\\\n",
    "                    or np.sum(masks_array[2*df.shape[0]+idx,:,:,:])<=15 or np.sum(masks_array[3*df.shape[0]+idx,:,:,:])<=15:\n",
    "                    print(\"smal\", patient_id, image_path, tm_file,np.asarray(nib.aff2axcodes(seg_affine)))\n",
    "        \n",
    "                #break\n",
    "            \n",
    "    masks_array=masks_array.astype(np.uint8)\n",
    "    #np.save(path_images_array, images_array)\n",
    "    #np.save(path_masks_array, masks_array)\n",
    "\n",
    "if True:\n",
    "    input_annotation_file = 'itmt2.0_joint.csv'\n",
    "    image_dir  = '../data/itmt2.0/'\n",
    "\n",
    "    df = pd.read_csv(input_annotation_file, header=0)\n",
    "    df_train = df[df['train/test']=='train'].reset_index()\n",
    "    #df_train=df_train[df_train['Ok registered? Y/N']=='Y'].reset_index()\n",
    "    df_val = df[df['train/test']=='val'].reset_index()\n",
    "    #df_val = df_val[df_val['Ok registered? Y/N']=='Y'].reset_index()\n",
    "    \n",
    "    nifty_to_npy(df_train, path_images_array='data/segmentations_itmt2.0/train_images.npy', \n",
    "                 path_masks_array='data/segmentations_itmt2.0/train_masks.npy')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9912f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id, image_path, tm_file, _ = get_id_and_path(df.iloc[200], image_dir= '../data/itmt2.0/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c03aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array, img_aff = load_nii(image_path)\n",
    "seg = nib.load(tm_file)\n",
    "seg_data, seg_affine  = seg.get_fdata(), seg.affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f01bbed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_label = np.asarray(np.where(seg_data != 0)).T[0, 2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c215d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.74242604, -1.74242604, -1.74242604, ..., -1.74242604,\n",
       "        -1.74242604, -1.74242604],\n",
       "       [-1.74242604, -1.74242604, -1.74242604, ..., -1.74242604,\n",
       "        -1.74242604, -1.74242604],\n",
       "       [-1.74242604, -1.74242604, -1.74242604, ..., -1.74242604,\n",
       "        -1.74242604, -1.74242604],\n",
       "       ...,\n",
       "       [-1.74242604, -1.74242604, -1.74242604, ..., -1.74242604,\n",
       "        -1.74242604, -1.74242604],\n",
       "       [-1.74242604, -1.74242604, -1.74242604, ..., -1.74242604,\n",
       "        -1.74242604, -1.74242604],\n",
       "       [-1.74242604, -1.74242604, -1.74242604, ..., -1.74242604,\n",
       "        -1.74242604, -1.74242604]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_array[:,:,slice_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8978b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3876df6",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b510ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in range(0, np.asarray(train_masks).shape[0]):\n",
    "    if np.sum(train_masks[img,:,:,0])<15:\n",
    "        print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba511a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1931bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_template_based_on_age(age):\n",
    "    for golden_file_path, age_values in age_ranges.items():\n",
    "        if age_values['min_age'] <= int(age) and int(age) <= age_values['max_age']: \n",
    "            print(golden_file_path)\n",
    "            return golden_file_path\n",
    "        \n",
    "def register_to_template(input_image_path, output_path, fixed_image_path,rename_id,create_subfolder=True):\n",
    "    fixed_image = itk.imread(fixed_image_path, itk.F)\n",
    "\n",
    "    # Import Parameter Map\n",
    "    parameter_object = itk.ParameterObject.New()\n",
    "    parameter_object.AddParameterFile('../shared_data/mni_templates/Parameters_Rigid.txt')\n",
    "\n",
    "    if \"nii\" in input_image_path and \"._\" not in input_image_path:\n",
    "        print(input_image_path)\n",
    "\n",
    "        # Call registration function\n",
    "        try:        \n",
    "            moving_image = itk.imread(input_image_path, itk.F)\n",
    "            result_image, result_transform_parameters = itk.elastix_registration_method(\n",
    "                fixed_image, moving_image,\n",
    "                parameter_object=parameter_object,\n",
    "                log_to_console=False)\n",
    "            image_id = input_image_path.split(\"/\")[-1]\n",
    "            \n",
    "            itk.imwrite(result_image, output_path+\"/\"+rename_id+\".nii.gz\")\n",
    "                \n",
    "            print(\"Registered \", rename_id)\n",
    "        except:\n",
    "            print(\"Cannot transform\", rename_id)\n",
    "           \n",
    "        \n",
    "def filter_islands(muscle_seg):\n",
    "    img = muscle_seg.astype('uint8')\n",
    "    contours, _ = cv2.findContours(img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    mask = np.zeros(img.shape, np.uint8)\n",
    "    cnt_mask = np.zeros(img.shape, np.uint8)\n",
    "    area = 0\n",
    "    c=0\n",
    "    if len(contours) != 0:\n",
    "        c = max(contours, key = cv2.contourArea)\n",
    "        area = cv2.contourArea(c)\n",
    "        mask = cv2.fillPoly(mask, pts=[c], color=(255, 0, 0))\n",
    "        cnt_mask =  cv2.drawContours(cnt_mask, [c], -1, (255, 255, 255), 0)#cv.drawContours(cnt_mask, [c], 0, (255,255,0), 2)\n",
    "    return mask, area, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a3e0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change paths to your data here\n",
    "img_path = '../shared_data/sub-pixar066_anat_sub-pixar066_T1w.nii.gz' # input raw t1 MRI path\n",
    "age = 7 # age of subject\n",
    "gender = \"F\" # gender\n",
    "model_weight_path_segmentation = '../model/unet_models/train/untitled_model_2023_07_07_00_12_09/Top_Segmentation_Model_Weight.hdf5'\n",
    "model_weight_path_selection = '../model/densenet_models/test/brisk-pyramid.hdf5'\n",
    "path_to = \"../output/\" # save to\n",
    "\n",
    "# MNI templates http://nist.mni.mcgill.ca/pediatric-atlases-4-5-18-5y/\n",
    "age_ranges = {\"../shared_data/mni_templates/nihpd_asym_04.5-08.5_t1w.nii\" : {\"min_age\":3, \"max_age\":7},\n",
    "                \"../shared_data/mni_templates/nihpd_asym_07.5-13.5_t1w.nii\": {\"min_age\":8, \"max_age\":13},\n",
    "                \"../shared_data/mni_templates/nihpd_asym_13.0-18.5_t1w.nii\": {\"min_age\":14, \"max_age\":35}}\n",
    "threshold = 0.75 # ie must be present on 3 out of 4 predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37470dce",
   "metadata": {},
   "source": [
    "### Preprocessing: register, rescale, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e25901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "image, affine = load_nii(img_path)\n",
    "plt.imshow(image[:,:,140])\n",
    "print(nib.aff2axcodes(affine))\n",
    "\n",
    "# path to store registered image in\n",
    "new_path_to = path_to+img_path.split(\"/\")[-1].split(\".\")[0]\n",
    "if not os.path.exists(new_path_to):\n",
    "    os.mkdir(new_path_to)\n",
    "\n",
    "# register image to MNI template\n",
    "golden_file_path = select_template_based_on_age(age)\n",
    "print(\"Registering to template:\", golden_file_path)\n",
    "register_to_template(img_path, new_path_to, golden_file_path,\"registered.nii.gz\", create_subfolder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebe8655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enchance and zscore normalize image\n",
    "if not os.path.exists(new_path_to+\"/no_z\"):\n",
    "    os.mkdir(new_path_to+\"/no_z\")\n",
    "    \n",
    "image_sitk =  sitk.ReadImage(new_path_to+\"/registered.nii.gz\")\n",
    "image_array  = sitk.GetArrayFromImage(image_sitk)\n",
    "image_array = enhance_noN4(image_array)\n",
    "image3 = sitk.GetImageFromArray(image_array)\n",
    "\n",
    "sitk.WriteImage(image3,new_path_to+\"/no_z/registered_no_z.nii\") \n",
    "cmd_line = \"zscore-normalize \"+new_path_to+\"/no_z/registered_no_z.nii -o \"+new_path_to+'/registered_z.nii'\n",
    "subprocess.getoutput(cmd_line)     \n",
    "print(cmd_line)\n",
    "print(\"Preprocessing done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70cc89d",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a2edd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "model_selection = DenseNet(img_dim=(256, 256, 1), \n",
    "                nb_layers_per_block=12, nb_dense_block=4, growth_rate=12, nb_initial_filters=16, \n",
    "                compression_rate=0.5, sigmoid_output_activation=True, \n",
    "                activation_type='relu', initializer='glorot_uniform', output_dimension=1, batch_norm=True )\n",
    "model_selection.load_weights(model_weight_path_selection)\n",
    "print('\\n','\\n','\\n','loaded:' ,model_weight_path_selection)  \n",
    "    \n",
    "model_unet = get_unet_2D(unet_classes,(target_size_unet[0], target_size_unet[1], 1),\\\n",
    "        num_convs=2,  activation='relu',\n",
    "        compression_channels=[16, 32, 64, 128, 256, 512],\n",
    "        decompression_channels=[256, 128, 64, 32, 16])\n",
    "model_unet.load_weights(model_weight_path_segmentation)\n",
    "print('\\n','\\n','\\n','loaded:' ,model_weight_path_segmentation)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ccacd1",
   "metadata": {},
   "source": [
    "### Inference - slice detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230b55fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_sitk = sitk.ReadImage(new_path_to+'/registered_z.nii')    \n",
    "windowed_images  = sitk.GetArrayFromImage(image_sitk)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec71c206",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_func = functools.partial(resize, output_shape=model_selection.input_shape[1:3],\n",
    "                                            preserve_range=True, anti_aliasing=True, mode='constant')\n",
    "series = np.dstack([resize_func(im) for im in windowed_images])\n",
    "series = np.transpose(series[:, :, :, np.newaxis], [2, 0, 1, 3])\n",
    "series_n = []\n",
    "\n",
    "for slice_idx in range(2, np.shape(series)[0]-2):\n",
    "    im_array = np.zeros((256, 256, 1, 5))\n",
    "    \n",
    "    # create MIP of 5 slices = 5mm \n",
    "    im_array[:,:,:,0] = series[slice_idx-2,:,:,:].astype(np.float32)\n",
    "    im_array[:,:,:,1] = series[slice_idx-1,:,:,:].astype(np.float32)\n",
    "    im_array[:,:,:,2] = series[slice_idx,:,:,:].astype(np.float32)\n",
    "    im_array[:,:,:,3] = series[slice_idx+1,:,:,:].astype(np.float32)\n",
    "    im_array[:,:,:,4] = series[slice_idx+2,:,:,:].astype(np.float32)\n",
    "            \n",
    "    im_array= np.max(im_array, axis=3)\n",
    "            \n",
    "    series_n.append(im_array)\n",
    "    series_w = np.dstack([funcy(im) for im in series_n])\n",
    "    series_w = np.transpose(series_w[:, :, :, np.newaxis], [2, 0, 1, 3])\n",
    "        \n",
    "predictions = model_selection.predict(series_w)\n",
    "slice_label = get_slice_number_from_prediction(predictions)\n",
    "print(\"Predicted slice:\", slice_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cafb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_array[:,:,slice_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c7fd5e",
   "metadata": {},
   "source": [
    "### Inference - segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3875742",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nib.load(new_path_to+'/registered_z.nii')  \n",
    "image_array, affine = img.get_fdata(), img.affine\n",
    "infer_seg_array_3d_1,infer_seg_array_3d_2 = np.zeros(image_array.shape),np.zeros(image_array.shape)\n",
    "print(np.asarray(nib.aff2axcodes(affine)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938352d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1344e1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale image into 512x512 for unet \n",
    "image_array_2d = rescale(image_array[:,15:-21,slice_label], scaling_factor).reshape(1,target_size_unet[0],target_size_unet[1],1) \n",
    "            \n",
    "img_half_11 = np.concatenate((image_array_2d[:,:256,:,:],np.zeros_like(image_array_2d[:,:256,:,:])),axis=1)\n",
    "img_half_21 = np.concatenate((np.zeros_like(image_array_2d[:,:256,:,:]),image_array_2d[:,:256,:,:]),axis=1)\n",
    "img_half_12 = np.concatenate((np.zeros_like(image_array_2d[:,256:,:,:]),image_array_2d[:,256:,:,:]),axis=1)\n",
    "img_half_22 = np.concatenate((image_array_2d[:,256:,:,:],np.zeros_like(image_array_2d[:,256:,:,:])),axis=1)\n",
    "\n",
    "flipped = np.flip(image_array_2d, axis=1)\n",
    "\n",
    "flipped_11 = np.concatenate((flipped[:,:256,:,:],np.zeros_like(flipped[:,:256,:,:])),axis=1)\n",
    "flipped_21 = np.concatenate((np.zeros_like(flipped[:,:256,:,:]),flipped[:,:256,:,:]),axis=1)\n",
    "flipped_12 = np.concatenate((np.zeros_like(flipped[:,256:,:,:]),flipped[:,256:,:,:]),axis=1)\n",
    "flipped_22 = np.concatenate((flipped[:,256:,:,:],np.zeros_like(flipped[:,256:,:,:])),axis=1)\n",
    "\n",
    "list_of_left_muscle = [img_half_11, img_half_21, flipped_12, flipped_22]\n",
    "list_of_right_muscle = [img_half_12,img_half_22, flipped_11, flipped_21]\n",
    "\n",
    "list_of_left_muscle_preds = []\n",
    "list_of_right_muscle_preds = []\n",
    "\n",
    "for image in list_of_left_muscle: \n",
    "    infer_seg_array = model_unet.predict(image)\n",
    "    muscle_seg = infer_seg_array[:,:,:,1].reshape(1,target_size_unet[0],target_size_unet[1],1)    \n",
    "    list_of_left_muscle_preds.append(muscle_seg)\n",
    "                    \n",
    "for image in list_of_right_muscle: \n",
    "    infer_seg_array = model_unet.predict(image)\n",
    "    muscle_seg = infer_seg_array[:,:,:,1].reshape(1,target_size_unet[0],target_size_unet[1],1)             \n",
    "    list_of_right_muscle_preds.append(muscle_seg)\n",
    "\n",
    "\n",
    "list_of_left_muscle_preds_halved = [list_of_left_muscle_preds[0][:,:256,:,:],\n",
    "                                    list_of_left_muscle_preds[1][:,256:,:,:],\n",
    "                                    np.flip(list_of_left_muscle_preds[2][:,256:,:,:],axis=1),\n",
    "                                    np.flip(list_of_left_muscle_preds[3][:,:256,:,:],axis=1)]\n",
    "\n",
    "list_of_right_muscle_preds_halved = [list_of_right_muscle_preds[0][:,256:,:,:],\n",
    "                                    list_of_right_muscle_preds[1][:,:256,:,:],\n",
    "                                    np.flip(list_of_right_muscle_preds[2][:,:256,:,:],axis=1),\n",
    "                                    np.flip(list_of_right_muscle_preds[3][:,256:,:,:],axis=1)]\n",
    "                \n",
    "left_half_result = np.mean(list_of_left_muscle_preds_halved, axis=0)>=threshold # <>\n",
    "right_half_result = np.mean(list_of_right_muscle_preds_halved, axis=0)>=threshold # <>\n",
    "muscle_seg_1 = np.concatenate((left_half_result,np.zeros_like(left_half_result)),axis=1)\n",
    "muscle_seg_2 = np.concatenate((np.zeros_like(left_half_result),right_half_result),axis=1)\n",
    "plt.imshow(muscle_seg_1[0,:,:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7be1d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(list_of_right_muscle_preds[3][0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388a0ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(flipped_12[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2431c842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f109402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8a650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_seg_array_3d_1_filtered,infer_seg_array_3d_2_filtered = np.zeros(image_array.shape),np.zeros(image_array.shape)\n",
    "infer_seg_array_3d_merged_filtered =  np.zeros(image_array.shape)\n",
    "        \n",
    "# filter islands\n",
    "muscle_seg_1_filtered, area_1, cnt_1 = filter_islands(muscle_seg_1[0])\n",
    "muscle_seg_2_filtered, area_2, cnt_2 = filter_islands(muscle_seg_2[0])\n",
    "\n",
    "# rescale for the unet\n",
    "infer_seg_array_2d_1 = rescale(muscle_seg_1[0],1/scaling_factor)\n",
    "infer_seg_array_2d_2 = rescale(muscle_seg_2[0],1/scaling_factor)\n",
    "infer_seg_array_2d_1_filtered = rescale(muscle_seg_1_filtered,1/scaling_factor)\n",
    "infer_seg_array_2d_2_filtered = rescale(muscle_seg_2_filtered,1/scaling_factor)\n",
    "\n",
    "# save to 3d\n",
    "infer_seg_array_3d_1[:,:,slice_label] = np.pad(infer_seg_array_2d_1[:,:,0],[[0,0],[15,21]],'constant',constant_values=0)\n",
    "infer_seg_array_3d_2[:,:,slice_label] = np.pad(infer_seg_array_2d_2[:,:,0],[[0,0],[15,21]],'constant',constant_values=0)\n",
    "infer_seg_array_3d_1_filtered[:,:,slice_label] = np.pad(infer_seg_array_2d_1_filtered[:,:,0],[[0,0],[15,21]],'constant',constant_values=0)\n",
    "infer_seg_array_3d_2_filtered[:,:,slice_label] = np.pad(infer_seg_array_2d_2_filtered[:,:,0],[[0,0],[15,21]],'constant',constant_values=0)\n",
    "            \n",
    "concated = np.concatenate((infer_seg_array_2d_1_filtered[:100,:,0],infer_seg_array_2d_2_filtered[100:,:,0]),axis=0)    \n",
    "infer_seg_array_3d_merged_filtered[:,:,slice_label] = np.pad(concated,[[0,0],[15,21]],'constant',constant_values=0)\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a348a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg=plt.figure(figsize=(5, 5), facecolor='k')\n",
    "plt.imshow(image_array_2d[0],'gray')\n",
    "plt.imshow(muscle_seg_1_filtered, 'gray', alpha=0.4, interpolation='none')\n",
    "plt.show()\n",
    "\n",
    "fg=plt.figure(figsize=(5, 5), facecolor='k')\n",
    "plt.imshow(image_array_2d[0],'gray')\n",
    "plt.imshow(muscle_seg_2_filtered, 'gray', alpha=0.4, interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9787ad71",
   "metadata": {},
   "source": [
    "### Compute TMT and CSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb8aea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_crop_line(img_input,infer_seg_array_2d_1,infer_seg_array_2d_2):\n",
    "    binary = img_input>-1.7\n",
    "    binary_smoothed = scipy.signal.medfilt(binary.astype(int), 51)\n",
    "    img = binary_smoothed.astype('uint8')\n",
    "    contours, _ = cv2.findContours(img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    mask = np.zeros(img.shape, np.uint8)\n",
    "    img = cv2.drawContours(mask, contours, -1, (255),1)\n",
    "\n",
    "    max_y,ind_max = 0,0\n",
    "    min_y,ind_min = 512,0\n",
    "    if len(contours)>0:\n",
    "        for i in range(0,len(contours[0])):\n",
    "            x,y = contours[0][i][0]\n",
    "            if y<=min_y:\n",
    "                min_y,ind_min = y,i\n",
    "            if y>=max_y:\n",
    "                max_y,ind_max = y,i\n",
    "        print(min_y,contours[0][ind_min][0])\n",
    "        print(max_y,contours[0][ind_max][0])\n",
    "\n",
    "        fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "        ax.imshow(img_input, interpolation=None, cmap=plt.cm.Greys_r)\n",
    "        ax.imshow(infer_seg_array_2d_1,cmap='jet',alpha=0.5)\n",
    "        ax.imshow(infer_seg_array_2d_2,cmap='jet',alpha=0.5)\n",
    "        crop_line = (contours[0][ind_min][0][0]+contours[0][ind_max][0][0])/2\n",
    "        \n",
    "        ax.plot((crop_line, crop_line),\n",
    "                (contours[0][ind_min][0][1], contours[0][ind_max][0][1]), lw=1, c='b')\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "        return crop_line\n",
    "    else:\n",
    "        return 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b06625",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_seg_array_2d_1 = rescale(muscle_seg_1_filtered,1/scaling_factor)\n",
    "infer_seg_array_2d_2 = rescale(muscle_seg_2_filtered,1/scaling_factor)\n",
    "\n",
    "infer_seg_array_3d_1[:,:,slice_label] = np.pad(infer_seg_array_2d_1[:,:,0],[[0,0],[15,21]],'constant',constant_values=0)\n",
    "infer_seg_array_3d_2[:,:,slice_label] = np.pad(infer_seg_array_2d_2[:,:,0],[[0,0],[15,21]],'constant',constant_values=0)\n",
    "\n",
    "objL_pred_minf_line, objR_pred_minf_line, objL_pred_minf, objR_pred_minf = 0,0,0,0\n",
    "                \n",
    "crop_line = compute_crop_line(image_array[:,15:-21,slice_label],infer_seg_array_2d_1,infer_seg_array_2d_2)\n",
    "                \n",
    "if np.sum(infer_seg_array_3d_1[:100,:,slice_label])>2:\n",
    "    objL_pred_minf = round(Calculater(infer_seg_array_3d_1[:100,:,slice_label], edge=True).minf,2)\n",
    "\n",
    "if np.sum(infer_seg_array_3d_2[100:,:,slice_label])>2:\n",
    "    objR_pred_minf = round(Calculater(infer_seg_array_3d_2[100:,:,slice_label], edge=True).minf,2)\n",
    "            \n",
    "CSA_PRED_TM1 = np.sum(infer_seg_array_3d_1[:100,:,slice_label])\n",
    "CSA_PRED_TM2 = np.sum(infer_seg_array_3d_2[100:,:,slice_label])\n",
    "                    \n",
    "if np.sum(infer_seg_array_3d_1[:100,int(crop_line):,slice_label])>2:\n",
    "    objL_pred_minf_line = round(Calculater(infer_seg_array_3d_1[:100,int(crop_line):,slice_label], edge=True).minf,2)\n",
    "\n",
    "if np.sum(infer_seg_array_3d_2[100:,int(crop_line):,slice_label])>2:\n",
    "    objR_pred_minf_line = round(Calculater(infer_seg_array_3d_2[100:,int(crop_line):,slice_label], edge=True).minf,2)\n",
    "                \n",
    "CSA_PRED_TM1_line = np.sum(infer_seg_array_3d_1[:100,int(crop_line):,slice_label])\n",
    "CSA_PRED_TM2_line = np.sum(infer_seg_array_3d_2[100:,int(crop_line):,slice_label])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c7c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "itmt = (Calculater(infer_seg_array_3d_1[:,:,slice_label], edge=True).minf +\n",
    "        Calculater(infer_seg_array_3d_2[:,:,slice_label], edge=True).minf)/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4e934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Calculater(infer_seg_array_3d_1[:,:,slice_label], edge=True).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c02488",
   "metadata": {},
   "outputs": [],
   "source": [
    "Calculater(infer_seg_array_3d_2[100:,:,slice_label], edge=True).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3236e419",
   "metadata": {},
   "source": [
    "## Compute centile for iTMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3fedc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_centile_boys = pd.read_csv('../data/percentiles_chart_boys.csv',header=0)\n",
    "df_centile_girls = pd.read_csv('../data/percentiles_chart_girls.csv',header=0)\n",
    "\n",
    "if gender==\"F\" or gender==\"f\" or gender==\"2\":\n",
    "    centile_dx = find_exact_percentile_return_number(itmt, age,df_centile_girls)\n",
    "else:\n",
    "    centile_dx = find_exact_percentile_return_number(itmt, age, df_centile_boys)\n",
    "\n",
    "print(\"Gender =\",gender,\"; Age =\",age,\"; iTMT =\",round(itmt,2), \"; Centile iTMT =\",centile_dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a81dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
